{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8256922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 184 clusters\n"
     ]
    }
   ],
   "source": [
    "# Load the filtered clusters CSV\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "CLUSTER_CSV = \"../results/filtered_NUMT_candidates.csv\"\n",
    "\n",
    "clusters = pd.read_csv(CLUSTER_CSV)\n",
    "clusters[\"num_split_reads\"] = 0\n",
    "\n",
    "print(f\"Loaded {len(clusters)} clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8266592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ref_name  bin_start  is_reverse  num_reads  avg_ref_start  avg_mate_start  \\\n",
      "0        1    1332000        True          2      1332031.0         11714.0   \n",
      "1        1    6461000        True          2      6461182.0         13807.0   \n",
      "2        1   16253000       False          2     16253019.0         10256.0   \n",
      "3        1   18841500       False          2     18841765.0          5177.0   \n",
      "4        1   51781000       False          2     51781162.0         13806.0   \n",
      "\n",
      "   num_split_reads  \n",
      "0               18  \n",
      "1               11  \n",
      "2                5  \n",
      "3                5  \n",
      "4                1  \n"
     ]
    }
   ],
   "source": [
    "# Build a read -> cluster mapping\n",
    "\n",
    "CLIPPED_READS_CLUSTER_CSV = \"../results/clipped_reads_with_cluster.csv\"\n",
    "clipped_df = pd.read_csv(CLIPPED_READS_CLUSTER_CSV)\n",
    "\n",
    "read_cluster_map = dict(zip(clipped_df[\"read_name\"], clipped_df[\"cluster_idx\"]))\n",
    "\n",
    "for cluster_idx in clipped_df[\"cluster_idx\"]:\n",
    "    clusters.at[cluster_idx, \"num_split_reads\"] += 1\n",
    "\n",
    "print(clusters.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24faee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "\n",
    "MT_BAM = \"../results/clipped_vs_mtDNA_sorted.bam\"\n",
    "bam = pysam.AlignmentFile(MT_BAM, \"rb\")\n",
    "\n",
    "for read in bam.fetch():\n",
    "    if read.is_unmapped:\n",
    "        continue\n",
    "\n",
    "    cluster_idx = read_cluster_map.get(read.query_name)\n",
    "    if cluster_idx is not None:\n",
    "        clusters.at[cluster_idx, \"num_split_reads\"] += 1\n",
    "\n",
    "bam.close()\n",
    "\n",
    "print(clusters[[\"ref_name\", \"bin_start\", \"num_reads\", \"num_split_reads\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c18da7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters before filtering: 184\n",
      "Clusters after filtering: 88\n"
     ]
    }
   ],
   "source": [
    "# Filter clusters again\n",
    "\n",
    "OUTPUT_CSV = \"../results/confirmed_NUMT_clusters.csv\"\n",
    "\n",
    "MIN_SPLIT_READS = 5\n",
    "\n",
    "confirmed_clusters = clusters[clusters[\"num_split_reads\"] >= MIN_SPLIT_READS]\n",
    "\n",
    "print(f\"Clusters before filtering: {len(clusters)}\")\n",
    "print(f\"Clusters after filtering: {len(confirmed_clusters)}\")\n",
    "\n",
    "confirmed_clusters.to_csv(OUTPUT_CSV, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinfo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
